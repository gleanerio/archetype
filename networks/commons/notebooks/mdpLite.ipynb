{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROt0OdUHCQjA"
   },
   "source": [
    "# Master Data Product Lite\n",
    "\n",
    "> NOTE:  this notebooks likely doesn't work yet\n",
    "\n",
    "<a href=\"https://githubtocolab.com/gleanerio/archetype/blob/master/networks/commons/mdpLite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.png\" alt=\"Open in Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBiniwAmCQjB"
   },
   "source": [
    "## requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpmar4p1Cerc"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q rdflib\n",
    "!pip install -q shapely\n",
    "!pip install -q pyld\n",
    "!pip install -q kglab\n",
    "!pip install -q minio\n",
    "!pip install -q objdict\n",
    "!pip install -q shapely\n",
    "!pip install -q geopandas\n",
    "!pip install -q oxrdflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DSr8qjAcsKs"
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bdz1-QBbCQjC",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:11:35.868303973Z",
     "start_time": "2023-12-12T14:11:34.833128665Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)  ## remove pandas future warning\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "# import s3fs\n",
    "import pyarrow.parquet as pq\n",
    "import shapely\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import json, io\n",
    "from pyld import jsonld\n",
    "import kglab\n",
    "from minio import Minio\n",
    "import rdflib\n",
    "from rdflib import ConjunctiveGraph  #  needed for nquads\n",
    "from urllib.request import urlopen\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from pyproj import Geod\n",
    "import oxrdflib # https://github.com/oxigraph/oxrdflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhnZ6kQM-1w3"
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tWmEYoqBwx6K",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:11:35.886860982Z",
     "start_time": "2023-12-12T14:11:35.874749282Z"
    }
   },
   "outputs": [],
   "source": [
    "# pop out last element in a quad to make a triple\n",
    "def popper(input):\n",
    "    lines = input.decode().split('\\n') # Split input into separate lines\n",
    "    modified_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        newline = line.replace(\"http://schema.org\", \"https://schema.org\")\n",
    "        segments = newline.split(' ')\n",
    "\n",
    "        if len(segments) > 3:\n",
    "            segments.pop()   # Remove the last two segment\n",
    "            segments.pop()\n",
    "            new_line = ' '.join(segments) + ' .'\n",
    "            modified_lines.append(new_line)\n",
    "\n",
    "    result_string = '\\n'.join(modified_lines)\n",
    "\n",
    "    return(result_string)\n",
    "\n",
    "def contextAlignment(input):\n",
    "    lines = input.decode().split('\\n') # Split input into separate lines\n",
    "    modified_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        newline = line.replace(\"http://schema.org\", \"https://schema.org\")\n",
    "\n",
    "        modified_lines.append(newline)\n",
    "\n",
    "    result_string = '\\n'.join(modified_lines)\n",
    "\n",
    "    return(result_string)\n",
    "\n",
    "def publicurls(client, bucket, prefix):\n",
    "    urls = []\n",
    "    objects = client.list_objects(bucket, prefix=prefix, recursive=True)\n",
    "    for obj in objects:\n",
    "        result = client.stat_object(bucket, obj.object_name)\n",
    "\n",
    "        if result.size > 0:  #  how to tell if an objet   obj.is_public  ?????\n",
    "            url = client.presigned_get_object(bucket, obj.object_name)\n",
    "            # print(f\"Public URL for object: {url}\")\n",
    "            urls.append(url)\n",
    "\n",
    "    return urls\n",
    "\n",
    "def to_wkt(polygon_string):\n",
    "    # split the input string into pairs\n",
    "    pairs = polygon_string.split(',')\n",
    "\n",
    "    # transform each pair into 'y x' format\n",
    "    # transformed_pairs = [' '.join(reversed(pair.split())) for pair in pairs]\n",
    "    transformed_pairs = [' '.join(pair.split()) for pair in pairs]\n",
    "\n",
    "\n",
    "    # join the transformed pairs with a comma and a space\n",
    "    transformed_string = ', '.join(transformed_pairs)\n",
    "\n",
    "    # return the final WKT string\n",
    "    return f\"POLYGON (({transformed_string}))\"\n",
    "\n",
    "def contains_alpha(s):\n",
    "    if isinstance(s, (int, float)):\n",
    "      return False\n",
    "    return any(c.isalpha() for c in s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cbs89hRsCQjF"
   },
   "source": [
    "\n",
    "## Load Graph(s)\n",
    "\n",
    "At this point we have the URLs, and we could either loop load all of them or pull one out manually and use.  This section dmonstrates loading and working with one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSvg2-PACQjE",
    "outputId": "f13a928e-aa36-4605-bb65-53a7cc3ee85f",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:11:38.792110298Z",
     "start_time": "2023-12-12T14:11:36.565116003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ossapi.oceaninfohub.org/public/graphs/summonedafricaioc_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedaquadocs_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedcioos_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonededmerp_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonededmo_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedemodnet_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedinanodc_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedinvemardocuments_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedinvemarexperts_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedinvemarinstitutions_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedinvemartraining_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedinvemarvessels_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedmarinetraining_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedobis_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedobps_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedoceanexperts_v1_release.nq\n",
      "http://ossapi.oceaninfohub.org/public/graphs/summonedpdh_v1_release.nq\n"
     ]
    }
   ],
   "source": [
    "client = Minio(\"ossapi.oceaninfohub.org:80\",  secure=False) # Create client with anonymous access.\n",
    "urls = publicurls(client, \"public\", \"graph\")\n",
    "for u in urls:\n",
    "  print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WbUIqG10CQjG",
    "outputId": "8a402c67-35fe-4266-ad1a-cdbf31d79e36",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:26:04.833153206Z",
     "start_time": "2023-12-12T14:25:57.076389788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145779\n"
     ]
    }
   ],
   "source": [
    "# load single quad graph into a RDFLIB conjunctive graph\n",
    "\n",
    "u = \"http://ossapi.oceaninfohub.org/public/graphs/summonedcioos_v1_release.nq\"\n",
    "# u = \"http://ossapi.oceaninfohub.org/public/graphs/summonedoceanexperts_v1_release.nq\"\n",
    "\n",
    "df = urlopen(u)\n",
    "dg = df.read()\n",
    "r = contextAlignment(dg)\n",
    "\n",
    "g = ConjunctiveGraph()\n",
    "# g = rdflib.ConjunctiveGraph(store=\"Oxigraph\")\n",
    "g.parse(data=r, format=\"nquads\")\n",
    "print(len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YrcfOITdCQjG",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:26:07.287084947Z",
     "start_time": "2023-12-12T14:26:07.273893286Z"
    }
   },
   "outputs": [],
   "source": [
    "## Convert the RDFLIB graph to a kglabs graph\n",
    "namespaces = {\n",
    "    \"sh\":   \"http://www.w3.org/ns/shacl#\" ,\n",
    "    \"schema\":   \"https://schema.org/\" ,\n",
    "    \"geo\":      \"http://www.opengis.net/ont/geosparql#\",\n",
    "}\n",
    "\n",
    "kg = kglab.KnowledgeGraph(name = \"OIH test\", base_uri = \"https://oceaninfohub.org/id/\", namespaces = namespaces, use_gpus=True, import_graph = g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEEcv606dro0"
   },
   "source": [
    "## Query Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "L7EVoF89cxWi",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:26:09.867896568Z",
     "start_time": "2023-12-12T14:26:08.763555958Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of URLs\n",
    "#     \"https://raw.githubusercontent.com/iodepo/odis-in/master/SPARQL/searchOIH/baseQuery.rq\",\n",
    "urls = [\n",
    "    \"https://raw.githubusercontent.com/iodepo/odis-in/master/SPARQL/searchOIH/baseQuery.rq\",\n",
    "    \"https://raw.githubusercontent.com/iodepo/odis-in/master/SPARQL/searchOIH/sup_geo.rq\",\n",
    "    \"https://raw.githubusercontent.com/iodepo/odis-in/master/SPARQL/searchOIH/address_geo.rq\",\n",
    "    \"https://raw.githubusercontent.com/iodepo/odis-in/master/SPARQL/searchOIH/sup_temporal.rq\",\n",
    "    \"https://raw.githubusercontent.com/iodepo/odis-in/master/SPARQL/searchOIH/dataset.rq\"\n",
    "]\n",
    "\n",
    "for url in urls:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            # Extract the file name from the URL and change \".rq\" to \"rq\"\n",
    "            file_name = url.split(\"/\")[-1].replace(\".rq\", \"rq\")\n",
    "            content = response.text\n",
    "\n",
    "            # Create a variable with the modified name and store the content\n",
    "            globals()[file_name] = content\n",
    "        else:\n",
    "            print(f\"Failed to download URL {url}. Status code: {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTbmGG9HeuXo",
    "outputId": "e0113455-9c8d-41e9-f935-dc860911c62b",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:26:27.942229790Z",
     "start_time": "2023-12-12T14:26:27.913804617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
      "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
      "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
      "prefix prov: <http://www.w3.org/ns/prov#>\n",
      "PREFIX schema: <https://schema.org/>\n",
      "\n",
      "\n",
      "SELECT DISTINCT (?s as ?id)  ?type ?name ?url ?description ?headline\n",
      "WHERE {\n",
      "         ?s rdf:type ?type .\n",
      "        OPTIONAL { ?s schema:name ?name . }\n",
      "        OPTIONAL { ?s schema:description ?description . }\n",
      "        OPTIONAL { ?s schema:url ?url . }\n",
      "        OPTIONAL { ?s schema:headline ?headline . }\n",
      " }\n"
     ]
    }
   ],
   "source": [
    "print(baseQueryrq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKPphnXlUYe1"
   },
   "source": [
    "## Loop on Queries\n",
    "\n",
    "NOTE, do the queries need isIRI for the subject to avoid resoruces without a top level ID?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9XcFOhLUX_n",
    "outputId": "86eaabd4-5c78-4191-88cc-c874940235cb",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:30:40.028137095Z",
     "start_time": "2023-12-12T14:26:32.121212123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29970\n",
      "516025\n",
      "2538\n",
      "5550\n"
     ]
    }
   ],
   "source": [
    "qlist = [baseQueryrq, datasetrq,  sup_georq, sup_temporalrq]\n",
    "\n",
    "# m1 = pd.merge(pdf, geodf, on='id', how='outer')\n",
    "# mf = pd.DataFrame()\n",
    "dfl = []\n",
    "for q in qlist:\n",
    "  df = kg.query_as_df(q)\n",
    "  print(len(df))\n",
    "  if len(df) > 0:\n",
    "    dfl.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZhIASbwN8hF3",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:31:27.316560639Z",
     "start_time": "2023-12-12T14:31:25.093380733Z"
    }
   },
   "outputs": [],
   "source": [
    "common_column = [\"id\", \"type\"]  # Replace with the actual common column name\n",
    "\n",
    "# Initialize a merged DataFrame with the first DataFrame\n",
    "merged_df = dfl[0]\n",
    "\n",
    "# Iterate through the remaining DataFrames and merge them into the merged_df\n",
    "for df in dfl[1:]:\n",
    "    merged_df = pd.merge(merged_df, df, on=common_column, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RglRhs44rXjt",
    "outputId": "81e2b9e7-6ef4-469b-b35d-1020948c3cad",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:31:28.116057047Z",
     "start_time": "2023-12-12T14:31:27.934334712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "2015"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XB6fIOW_bOSL",
    "outputId": "ebdd4946-bbbe-4d0f-f8e7-1d36e1037e6e",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:31:29.056336454Z",
     "start_time": "2023-12-12T14:31:29.053455349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2670330 entries, 0 to 2670329\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Dtype \n",
      "---  ------                 ----- \n",
      " 0   id                     object\n",
      " 1   type                   object\n",
      " 2   name_x                 object\n",
      " 3   url_x                  object\n",
      " 4   description_x          object\n",
      " 5   name_y                 object\n",
      " 6   url_y                  object\n",
      " 7   description_y          object\n",
      " 8   license                object\n",
      " 9   keywords               object\n",
      " 10  includedInDataCatalog  object\n",
      " 11  distribution           object\n",
      " 12  provider               object\n",
      " 13  publisher              object\n",
      " 14  creator                object\n",
      " 15  geotype                object\n",
      " 16  geompred               object\n",
      " 17  geom                   object\n",
      " 18  temporalCoverage       object\n",
      " 19  datePublished          object\n",
      "dtypes: object(20)\n",
      "memory usage: 427.8+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJpmnVCGzamw"
   },
   "source": [
    "## Post processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJbUhtXp4t8a"
   },
   "source": [
    "### GeoSpatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Mi3173QJzeCV",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:31:39.131165029Z",
     "start_time": "2023-12-12T14:31:33.819071736Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_df['filteredgeom'] = merged_df['geom'].apply(lambda x: np.nan if contains_alpha(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCvbGG7o5HJy"
   },
   "source": [
    "### Regions\n",
    "Incorporate Jeff's regions.py which needs\n",
    "\n",
    "* address (Org, person, Course?\n",
    "* name (THING, in all)\n",
    "* spatialFeature (WKT geom column)\n",
    "* countryOfLastProcessing (vehicle only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jVbZ1sheLbn2",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:31:40.708021556Z",
     "start_time": "2023-12-12T14:31:40.697727810Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize(s):\n",
    "    if isinstance(s, str):\n",
    "      s = s.lower()\n",
    "      s = re.sub(r\"\\(.*\\)\",\"\",s)\n",
    "      s = re.sub(r\"\\[.*\\]\",\"\",s)\n",
    "      s = re.sub(r\"and|the|of\",\"\", s)\n",
    "      s = s.rstrip('.')\n",
    "      return set(s.split(None))\n",
    "    else:\n",
    "      return set(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "TT3LHNQOKMC-",
    "outputId": "b64b39f3-8d25-4a5f-80f1-cf37a2ead07c",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:32:32.406696188Z",
     "start_time": "2023-12-12T14:32:30.636053361Z"
    }
   },
   "outputs": [],
   "source": [
    "# from . import datashaping\n",
    "import shapely.geometry\n",
    "import os, json\n",
    "\n",
    "import shapely.wkt\n",
    "import shapely.geometry\n",
    "from urllib.request import urlopen\n",
    "\n",
    "with open('./assets/regions-clipped.geojson', 'r') as f:\n",
    "    geo_regions = json.load(f)['features']\n",
    "    for r in geo_regions:\n",
    "        r['shape'] = shapely.geometry.shape(r['geometry'])\n",
    "\n",
    "# leverage the UNSD API \"GeoArea\" JSON endpoint, instead of locally-stored CSV\n",
    "#  see https://unstats.un.org/SDGAPI/swagger/\n",
    "unsdGeoareaEndpoint = \"https://unstats.un.org/SDGAPI/v1/sdg/GeoArea/Tree\"\n",
    "response = urlopen(unsdGeoareaEndpoint)\n",
    "unsdDataJSON = json.loads(response.read())\n",
    "\n",
    "# use the \"World (total) by continental regions\" branch\n",
    "continentalRegions = unsdDataJSON[1]\n",
    "continentalRegionsChildren = continentalRegions['children']\n",
    "\n",
    "# parse the JSON from the API call\n",
    "countries_dict_with_regions = {}\n",
    "country_map_list = []\n",
    "\n",
    "for list_regions in continentalRegionsChildren:\n",
    "    if list_regions['children'] == None:\n",
    "        regionName = list_regions['geoAreaName']\n",
    "        # print('Region name (no children): ' + regionName)\n",
    "    else:\n",
    "        regionName = list_regions['geoAreaName']\n",
    "        # print('Region name: ' + regionName)\n",
    "        # loop through sub-regions\n",
    "        for list_subregions in list_regions['children']:\n",
    "            subRegionName = list_subregions['geoAreaName']\n",
    "            # print('Sub-region name: ' + subRegionName)\n",
    "            # loop through intermediate region items\n",
    "            for list_intermediate_regions in list_subregions['children']:\n",
    "                if list_intermediate_regions['type'] == 'Region':\n",
    "                    intermediateRegionName = list_intermediate_regions['geoAreaName']\n",
    "                    # print('Intermediate region name: ' + intermediateRegionName)\n",
    "                    # loop through intermediate region children\n",
    "                    for list_intermediate_region_children in list_intermediate_regions['children']:\n",
    "                        countryName = list_intermediate_region_children['geoAreaName'].lower()\n",
    "                        # print('Country name: ' + countryName)\n",
    "                        countries_dict_with_regions[countryName] = [regionName, subRegionName]\n",
    "                        country_map_list.append((normalize(countryName), countryName))\n",
    "                else:\n",
    "                    countryName = list_intermediate_regions['geoAreaName'].lower()\n",
    "                    # print('Country name: ' + countryName)\n",
    "                    countries_dict_with_regions[countryName] = [regionName, subRegionName]\n",
    "                    country_map_list.append((normalize(countryName), countryName))\n",
    "\n",
    "\n",
    "def address(address):\n",
    "    normalized = normalize(address)\n",
    "    value = list()\n",
    "    for parts, country in country_map_list:\n",
    "        if parts <= normalized:\n",
    "          if country in countries_dict_with_regions:\n",
    "            value = countries_dict_with_regions[country]\n",
    "    return value\n",
    "\n",
    "def name(n):\n",
    "    normalized = normalize(n)\n",
    "    value = list()\n",
    "    for parts, country in country_map_list:\n",
    "      if parts <= normalized:\n",
    "        if country in countries_dict_with_regions:\n",
    "          value = countries_dict_with_regions[country]\n",
    "    return value\n",
    "\n",
    "\n",
    "def countryLastProcessing(countryOfLastProcessing):\n",
    "    normalized = normalize(countryOfLastProcessing)\n",
    "    value = list()\n",
    "    for parts, country in country_map_list:\n",
    "        if parts <= normalized:\n",
    "          if country in countries_dict_with_regions:\n",
    "            value = countries_dict_with_regions[country]\n",
    "    return value\n",
    "\n",
    "\n",
    "def feature(feature):\n",
    "    try:\n",
    "        the_geom = shapely.wkt.loads(feature)\n",
    "        return [r['properties']['name'] for r in geo_regions if r['shape'].intersects(the_geom)]\n",
    "    except:\n",
    "        print(\"Invalid WKT\")\n",
    "        return list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "X6k7-XQ_fLOF",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:32:33.196999234Z",
     "start_time": "2023-12-12T14:32:33.155632486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                name\n0            Marine Science Country Profiles : Kenya\n1  The fisheries of Barbados and some of their pr...\n2                           Fiji : Where's the data?\n3  POLYGON ((-95.5 19.5,-95.5 31.5,-73.5 31.5,-73...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Marine Science Country Profiles : Kenya</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The fisheries of Barbados and some of their pr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Fiji : Where's the data?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>POLYGON ((-95.5 19.5,-95.5 31.5,-73.5 31.5,-73...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data1 = [\"Marine Science Country Profiles : Kenya\",\n",
    "        \"The fisheries of Barbados and some of their problems\",\n",
    "        \"Fiji : Where's the data?\", 'POLYGON ((-95.5 19.5,-95.5 31.5,-73.5 31.5,-73.5 19.5,-95.5 19.5))']\n",
    "\n",
    "data2 = [\"Marine Science Country Profiles : Kenya\",\n",
    "        \"The fisheries of Barbados and some of their problems\",\n",
    "        \"Fiji : Where's the data?\"]\n",
    "\n",
    "dftest = pd.DataFrame({'name': data1})\n",
    "dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "5eGk_NE8Uw0O",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:32:35.389095743Z",
     "start_time": "2023-12-12T14:32:35.344508641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid WKT\n",
      "Invalid WKT\n",
      "Invalid WKT\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                name  \\\n0            Marine Science Country Profiles : Kenya   \n1  The fisheries of Barbados and some of their pr...   \n2                           Fiji : Where's the data?   \n3  POLYGON ((-95.5 19.5,-95.5 31.5,-73.5 31.5,-73...   \n\n                                       nregion  \\\n0                 [Africa, Sub-Saharan Africa]   \n1  [Americas, Latin America and the Caribbean]   \n2                         [Oceania, Melanesia]   \n3                                           []   \n\n                                       aregion  \\\n0                 [Africa, Sub-Saharan Africa]   \n1  [Americas, Latin America and the Caribbean]   \n2                         [Oceania, Melanesia]   \n3                                           []   \n\n                                       cregion  \\\n0                 [Africa, Sub-Saharan Africa]   \n1  [Americas, Latin America and the Caribbean]   \n2                         [Oceania, Melanesia]   \n3                                           []   \n\n                                             fregion  \n0                                                 []  \n1                                                 []  \n2                                                 []  \n3  [Caribbean Sea, Atlantic Ocean, Latin America ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>nregion</th>\n      <th>aregion</th>\n      <th>cregion</th>\n      <th>fregion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Marine Science Country Profiles : Kenya</td>\n      <td>[Africa, Sub-Saharan Africa]</td>\n      <td>[Africa, Sub-Saharan Africa]</td>\n      <td>[Africa, Sub-Saharan Africa]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The fisheries of Barbados and some of their pr...</td>\n      <td>[Americas, Latin America and the Caribbean]</td>\n      <td>[Americas, Latin America and the Caribbean]</td>\n      <td>[Americas, Latin America and the Caribbean]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Fiji : Where's the data?</td>\n      <td>[Oceania, Melanesia]</td>\n      <td>[Oceania, Melanesia]</td>\n      <td>[Oceania, Melanesia]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>POLYGON ((-95.5 19.5,-95.5 31.5,-73.5 31.5,-73...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[Caribbean Sea, Atlantic Ocean, Latin America ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged_df['region'] = merged_df['name'].apply(lambda x: x + [item for item in name(x) if item not in x] if x else x)\n",
    "dftest['nregion'] = dftest['name'].apply(lambda x: name(x)  if x else x)\n",
    "dftest['aregion'] = dftest['name'].apply(lambda x: address(x)  if x else x)\n",
    "dftest['cregion'] = dftest['name'].apply(lambda x: countryLastProcessing(x)  if x else x)\n",
    "dftest['fregion'] = dftest['name'].apply(lambda x: feature(x)  if x else x)\n",
    "\n",
    "dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CFQEfLr-xKVi",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:32:39.331093548Z",
     "start_time": "2023-12-12T14:32:39.328013439Z"
    }
   },
   "outputs": [],
   "source": [
    "def g(df):\n",
    "    df['region'] = df[['nregion', 'aregion','cregion', 'fregion']].apply(lambda x: list(set(x[0] + x[1] + x[2]+ x[3])), axis=1)\n",
    "    del df['nregion']\n",
    "    del df['aregion']\n",
    "    del df['cregion']\n",
    "    del df['fregion']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "gVqOudG4xfk4",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:32:40.612725645Z",
     "start_time": "2023-12-12T14:32:40.600303562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                name  \\\n0            Marine Science Country Profiles : Kenya   \n1  The fisheries of Barbados and some of their pr...   \n2                           Fiji : Where's the data?   \n3  POLYGON ((-95.5 19.5,-95.5 31.5,-73.5 31.5,-73...   \n\n                                              region  \n0                       [Africa, Sub-Saharan Africa]  \n1        [Americas, Latin America and the Caribbean]  \n2                               [Melanesia, Oceania]  \n3  [Atlantic Ocean, Caribbean Sea, Latin America ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Marine Science Country Profiles : Kenya</td>\n      <td>[Africa, Sub-Saharan Africa]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The fisheries of Barbados and some of their pr...</td>\n      <td>[Americas, Latin America and the Caribbean]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Fiji : Where's the data?</td>\n      <td>[Melanesia, Oceania]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>POLYGON ((-95.5 19.5,-95.5 31.5,-73.5 31.5,-73...</td>\n      <td>[Atlantic Ocean, Caribbean Sea, Latin America ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest = g(dftest.copy())\n",
    "\n",
    "dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "7igZku159VNZ",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:32:42.155999485Z",
     "start_time": "2023-12-12T14:32:42.149621659Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_pairs(ll):\n",
    "  \"\"\"Makes pairs of coordinates from a list of coordinates.\n",
    "\n",
    "  Args:\n",
    "    ll: A list of coordinates.\n",
    "\n",
    "  Returns:\n",
    "    A list of pairs of coordinates.\n",
    "  \"\"\"\n",
    "\n",
    "  coords = []\n",
    "  for i in range(0, len(ll), 2):\n",
    "    coords.append((ll[i], ll[i+1]))\n",
    "\n",
    "  return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "96AMKBOGRngl",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:32:43.213762865Z",
     "start_time": "2023-12-12T14:32:43.206522941Z"
    }
   },
   "outputs": [],
   "source": [
    "def gj(geom, value):\n",
    "  test = geom.split()\n",
    "  test = [float(x) for x in test]\n",
    "  if len(test) < 2:\n",
    "    return None\n",
    "\n",
    "  cp = make_pairs(test)\n",
    "\n",
    "  if len(cp) == 1:\n",
    "    # print(\"POINT\")\n",
    "    geom = shapely.Point(cp)\n",
    "  elif len(cp) == 2:\n",
    "    # print(\"BOX\")\n",
    "    geom = shapely.box(cp[0][0], cp[0][1], cp[1][0], cp[1][1])\n",
    "  else:\n",
    "    # print(\"POLYGON\")\n",
    "    geom = shapely.Polygon(cp)\n",
    "\n",
    "  if value == \"centroid\":\n",
    "    return geom.centroid\n",
    "  elif value == \"length\":\n",
    "    return geom.length\n",
    "  elif value == \"area\":\n",
    "    geod = Geod(ellps=\"WGS84\")\n",
    "    area = abs(geod.geometry_area_perimeter(geom)[0])\n",
    "    return area\n",
    "  elif value == \"wkt\":\n",
    "    return shapely.to_wkt(geom)\n",
    "  elif value == \"geojson\":\n",
    "    return shapely.to_geojson(geom)\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "vizQZ3imRwmQ",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:37:34.158644338Z",
     "start_time": "2023-12-12T14:32:44.168744213Z"
    }
   },
   "outputs": [],
   "source": [
    "# merged_df['dt_endDate'] = merged_df['temporalCoverage'].apply(lambda x: re.split(\"/\", x)[1] if \"/\" in x else np.nan)\n",
    "\n",
    "merged_df['centroid'] = merged_df['filteredgeom'].apply(lambda x: gj(str(x), \"centroid\"))\n",
    "merged_df['length'] = merged_df['filteredgeom'].apply(lambda x: gj(str(x), \"length\"))\n",
    "merged_df['area'] = merged_df['filteredgeom'].apply(lambda x: gj(str(x), \"area\"))\n",
    "merged_df['wkt'] = merged_df['filteredgeom'].apply(lambda x: gj(str(x), \"wkt\"))\n",
    "merged_df['geojson'] = merged_df['filteredgeom'].apply(lambda x: gj(str(x), \"geojson\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "6Mp4_0kQ5MQr",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:37:36.491511001Z",
     "start_time": "2023-12-12T14:37:36.474255970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLYGON ((47.974647 -129.08715, 47.974647 -129.08715, 47.974647 -129.08715, 47.974647 -129.08715, 47.974647 -129.08715))\n"
     ]
    }
   ],
   "source": [
    "# merged_df[].head()\n",
    "print(merged_df[\"wkt\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxZrniVD4w5o"
   },
   "source": [
    "### Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "1F8-w8pBzdxZ",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:39:36.657118844Z",
     "start_time": "2023-12-12T14:37:37.953094728Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_df['temporalCoverage'] = merged_df['temporalCoverage'].astype('str')  # fine to make str since we don't use in the solr JSON\n",
    "merged_df['dt_startDate'] = merged_df['temporalCoverage'].apply(lambda x: re.split(\"/\", x)[0] if \"/\" in x else np.nan)\n",
    "merged_df['dt_endDate'] = merged_df['temporalCoverage'].apply(lambda x: re.split(\"/\", x)[1] if \"/\" in x else np.nan)\n",
    "merged_df['n_startYear'] = merged_df['dt_startDate'].apply(lambda x: parser.parse(x).year if \"-\" in str(x) else np.nan)\n",
    "merged_df['n_endYear'] = merged_df['dt_endDate'].apply(lambda x: parser.parse(x).year if \"-\" in str(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "DV2Z7Jq5PqBN",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:39:50.909398622Z",
     "start_time": "2023-12-12T14:39:50.895576560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2670330 entries, 0 to 2670329\n",
      "Data columns (total 30 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   id                     object \n",
      " 1   type                   object \n",
      " 2   name_x                 object \n",
      " 3   url_x                  object \n",
      " 4   description_x          object \n",
      " 5   name_y                 object \n",
      " 6   url_y                  object \n",
      " 7   description_y          object \n",
      " 8   license                object \n",
      " 9   keywords               object \n",
      " 10  includedInDataCatalog  object \n",
      " 11  distribution           object \n",
      " 12  provider               object \n",
      " 13  publisher              object \n",
      " 14  creator                object \n",
      " 15  geotype                object \n",
      " 16  geompred               object \n",
      " 17  geom                   object \n",
      " 18  temporalCoverage       object \n",
      " 19  datePublished          object \n",
      " 20  filteredgeom           object \n",
      " 21  centroid               object \n",
      " 22  length                 float64\n",
      " 23  area                   float64\n",
      " 24  wkt                    object \n",
      " 25  geojson                object \n",
      " 26  dt_startDate           object \n",
      " 27  dt_endDate             object \n",
      " 28  n_startYear            float64\n",
      " 29  n_endYear              float64\n",
      "dtypes: float64(4), object(26)\n",
      "memory usage: 631.6+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "8WvtX_xp0tjo",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:39:52.245635568Z",
     "start_time": "2023-12-12T14:39:52.230667644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  id            type  \\\n0  <https://catalogue.cioos.ca/dataset/2d2f65b5-c...  schema:Dataset   \n1  <https://catalogue.cioos.ca/dataset/2d2f65b5-c...  schema:Dataset   \n2  <https://catalogue.cioos.ca/dataset/2d2f65b5-c...  schema:Dataset   \n3  <https://catalogue.cioos.ca/dataset/2d2f65b5-c...  schema:Dataset   \n4  <https://catalogue.cioos.ca/dataset/2d2f65b5-c...  schema:Dataset   \n\n                                              name_x  \\\n0  Endeavour North Conductivité/Température/Profo...   \n1  Endeavour North Conductivité/Température/Profo...   \n2  Endeavour North Conductivité/Température/Profo...   \n3  Endeavour North Conductivité/Température/Profo...   \n4  Endeavour North Conductivité/Température/Profo...   \n\n                                               url_x  \\\n0  https://catalogue.cioos.ca/dataset/2d2f65b5-ca...   \n1  https://catalogue.cioos.ca/dataset/2d2f65b5-ca...   \n2  https://catalogue.cioos.ca/dataset/2d2f65b5-ca...   \n3  https://catalogue.cioos.ca/dataset/2d2f65b5-ca...   \n4  https://catalogue.cioos.ca/dataset/2d2f65b5-ca...   \n\n                                       description_x  \\\n0  Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...   \n1  Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...   \n2  Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...   \n3  Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...   \n4  Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...   \n\n                                              name_y  \\\n0  Endeavour North Conductivité/Température/Profo...   \n1  Endeavour North Conductivité/Température/Profo...   \n2  Endeavour North Conductivité/Température/Profo...   \n3  Endeavour North Conductivité/Température/Profo...   \n4  Endeavour North Conductivité/Température/Profo...   \n\n                                               url_y  \\\n0  https://catalogue.cioos.ca/dataset/2d2f65b5-ca...   \n1  https://catalogue.cioos.ca/dataset/2d2f65b5-ca...   \n2  https://catalogue.cioos.ca/dataset/2d2f65b5-ca...   \n3  https://catalogue.cioos.ca/dataset/2d2f65b5-ca...   \n4  https://catalogue.cioos.ca/dataset/2d2f65b5-ca...   \n\n                                       description_y license keywords  ...  \\\n0  Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...    None   Oceans  ...   \n1  Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...    None   Oceans  ...   \n2  Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...    None   Oceans  ...   \n3  Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...    None   Oceans  ...   \n4  Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...    None   Oceans  ...   \n\n                                      filteredgeom  \\\n0  47.974646666 -129.08715 47.974646666 -129.08715   \n1  47.974646666 -129.08715 47.974646666 -129.08715   \n2  47.974646666 -129.08715 47.974646666 -129.08715   \n3  47.974646666 -129.08715 47.974646666 -129.08715   \n4  47.974646666 -129.08715 47.974646666 -129.08715   \n\n                          centroid length area  \\\n0  POINT (47.974646666 -129.08715)    0.0  NaN   \n1  POINT (47.974646666 -129.08715)    0.0  NaN   \n2  POINT (47.974646666 -129.08715)    0.0  NaN   \n3  POINT (47.974646666 -129.08715)    0.0  NaN   \n4  POINT (47.974646666 -129.08715)    0.0  NaN   \n\n                                                 wkt  \\\n0  POLYGON ((47.974647 -129.08715, 47.974647 -129...   \n1  POLYGON ((47.974647 -129.08715, 47.974647 -129...   \n2  POLYGON ((47.974647 -129.08715, 47.974647 -129...   \n3  POLYGON ((47.974647 -129.08715, 47.974647 -129...   \n4  POLYGON ((47.974647 -129.08715, 47.974647 -129...   \n\n                                             geojson dt_startDate  dt_endDate  \\\n0  {\"type\":\"Polygon\",\"coordinates\":[[[47.97464666...   2018-06-28  2021-08-24   \n1  {\"type\":\"Polygon\",\"coordinates\":[[[47.97464666...   2018-06-28  2021-08-24   \n2  {\"type\":\"Polygon\",\"coordinates\":[[[47.97464666...   2018-06-28  2021-08-24   \n3  {\"type\":\"Polygon\",\"coordinates\":[[[47.97464666...   2018-06-28  2021-08-24   \n4  {\"type\":\"Polygon\",\"coordinates\":[[[47.97464666...   2018-06-28  2021-08-24   \n\n  n_startYear n_endYear  \n0      2018.0    2021.0  \n1      2018.0    2021.0  \n2      2018.0    2021.0  \n3      2018.0    2021.0  \n4      2018.0    2021.0  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>type</th>\n      <th>name_x</th>\n      <th>url_x</th>\n      <th>description_x</th>\n      <th>name_y</th>\n      <th>url_y</th>\n      <th>description_y</th>\n      <th>license</th>\n      <th>keywords</th>\n      <th>...</th>\n      <th>filteredgeom</th>\n      <th>centroid</th>\n      <th>length</th>\n      <th>area</th>\n      <th>wkt</th>\n      <th>geojson</th>\n      <th>dt_startDate</th>\n      <th>dt_endDate</th>\n      <th>n_startYear</th>\n      <th>n_endYear</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;https://catalogue.cioos.ca/dataset/2d2f65b5-c...</td>\n      <td>schema:Dataset</td>\n      <td>Endeavour North Conductivité/Température/Profo...</td>\n      <td>https://catalogue.cioos.ca/dataset/2d2f65b5-ca...</td>\n      <td>Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...</td>\n      <td>Endeavour North Conductivité/Température/Profo...</td>\n      <td>https://catalogue.cioos.ca/dataset/2d2f65b5-ca...</td>\n      <td>Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...</td>\n      <td>None</td>\n      <td>Oceans</td>\n      <td>...</td>\n      <td>47.974646666 -129.08715 47.974646666 -129.08715</td>\n      <td>POINT (47.974646666 -129.08715)</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>POLYGON ((47.974647 -129.08715, 47.974647 -129...</td>\n      <td>{\"type\":\"Polygon\",\"coordinates\":[[[47.97464666...</td>\n      <td>2018-06-28</td>\n      <td>2021-08-24</td>\n      <td>2018.0</td>\n      <td>2021.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;https://catalogue.cioos.ca/dataset/2d2f65b5-c...</td>\n      <td>schema:Dataset</td>\n      <td>Endeavour North Conductivité/Température/Profo...</td>\n      <td>https://catalogue.cioos.ca/dataset/2d2f65b5-ca...</td>\n      <td>Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...</td>\n      <td>Endeavour North Conductivité/Température/Profo...</td>\n      <td>https://catalogue.cioos.ca/dataset/2d2f65b5-ca...</td>\n      <td>Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...</td>\n      <td>None</td>\n      <td>Oceans</td>\n      <td>...</td>\n      <td>47.974646666 -129.08715 47.974646666 -129.08715</td>\n      <td>POINT (47.974646666 -129.08715)</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>POLYGON ((47.974647 -129.08715, 47.974647 -129...</td>\n      <td>{\"type\":\"Polygon\",\"coordinates\":[[[47.97464666...</td>\n      <td>2018-06-28</td>\n      <td>2021-08-24</td>\n      <td>2018.0</td>\n      <td>2021.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;https://catalogue.cioos.ca/dataset/2d2f65b5-c...</td>\n      <td>schema:Dataset</td>\n      <td>Endeavour North Conductivité/Température/Profo...</td>\n      <td>https://catalogue.cioos.ca/dataset/2d2f65b5-ca...</td>\n      <td>Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...</td>\n      <td>Endeavour North Conductivité/Température/Profo...</td>\n      <td>https://catalogue.cioos.ca/dataset/2d2f65b5-ca...</td>\n      <td>Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...</td>\n      <td>None</td>\n      <td>Oceans</td>\n      <td>...</td>\n      <td>47.974646666 -129.08715 47.974646666 -129.08715</td>\n      <td>POINT (47.974646666 -129.08715)</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>POLYGON ((47.974647 -129.08715, 47.974647 -129...</td>\n      <td>{\"type\":\"Polygon\",\"coordinates\":[[[47.97464666...</td>\n      <td>2018-06-28</td>\n      <td>2021-08-24</td>\n      <td>2018.0</td>\n      <td>2021.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;https://catalogue.cioos.ca/dataset/2d2f65b5-c...</td>\n      <td>schema:Dataset</td>\n      <td>Endeavour North Conductivité/Température/Profo...</td>\n      <td>https://catalogue.cioos.ca/dataset/2d2f65b5-ca...</td>\n      <td>Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...</td>\n      <td>Endeavour North Conductivité/Température/Profo...</td>\n      <td>https://catalogue.cioos.ca/dataset/2d2f65b5-ca...</td>\n      <td>Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...</td>\n      <td>None</td>\n      <td>Oceans</td>\n      <td>...</td>\n      <td>47.974646666 -129.08715 47.974646666 -129.08715</td>\n      <td>POINT (47.974646666 -129.08715)</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>POLYGON ((47.974647 -129.08715, 47.974647 -129...</td>\n      <td>{\"type\":\"Polygon\",\"coordinates\":[[[47.97464666...</td>\n      <td>2018-06-28</td>\n      <td>2021-08-24</td>\n      <td>2018.0</td>\n      <td>2021.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;https://catalogue.cioos.ca/dataset/2d2f65b5-c...</td>\n      <td>schema:Dataset</td>\n      <td>Endeavour North Conductivité/Température/Profo...</td>\n      <td>https://catalogue.cioos.ca/dataset/2d2f65b5-ca...</td>\n      <td>Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...</td>\n      <td>Endeavour North Conductivité/Température/Profo...</td>\n      <td>https://catalogue.cioos.ca/dataset/2d2f65b5-ca...</td>\n      <td>Ce Sea-Bird Microcat SBE37SIP 5695 a été déplo...</td>\n      <td>None</td>\n      <td>Oceans</td>\n      <td>...</td>\n      <td>47.974646666 -129.08715 47.974646666 -129.08715</td>\n      <td>POINT (47.974646666 -129.08715)</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>POLYGON ((47.974647 -129.08715, 47.974647 -129...</td>\n      <td>{\"type\":\"Polygon\",\"coordinates\":[[[47.97464666...</td>\n      <td>2018-06-28</td>\n      <td>2021-08-24</td>\n      <td>2018.0</td>\n      <td>2021.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "x_b5cg711tVx",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:40:50.916619316Z",
     "start_time": "2023-12-12T14:40:34.607293670Z"
    }
   },
   "outputs": [],
   "source": [
    "# transforms needed for aggregation\n",
    "merged_df['keywords'] = merged_df['keywords'].astype(str)  #  why is this needed?\n",
    "\n",
    "\n",
    "if \"geom\" in merged_df.columns:\n",
    "    merged_df['geom'] = merged_df['geom'].astype(str)  # why is this needed?\n",
    "    merged_df['filteredgeom'] = merged_df['filteredgeom'].astype(str)  # why is this needed?\n",
    "    merged_df['centroid'] = merged_df['centroid'].astype(str)  # why is this needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "ehVW6ZHuzeP0",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:41:17.208025617Z",
     "start_time": "2023-12-12T14:41:17.190539149Z"
    }
   },
   "outputs": [],
   "source": [
    "agg_dict = {'keywords': ', '.join,\n",
    "            'type': 'first',\n",
    "            'name': ', '.join,\n",
    "            'description': ', '.join,\n",
    "            'url': ', '.join,\n",
    "            'geotype': 'first',\n",
    "            'geompred': 'first',\n",
    "            'geom': 'first',\n",
    "            'temporalCoverage': 'first',\n",
    "            'datePublished': 'first',\n",
    "            'license': 'first',\n",
    "            'creator': 'first',\n",
    "            'includedInDataCatalog': 'first',\n",
    "            'distribution': 'first',\n",
    "            'publisher': 'first',\n",
    "            'filteredgeom': 'first',\n",
    "            'region': 'first',\n",
    "            'dt_startDate': 'first',\n",
    "            'dt_endDate': 'first',\n",
    "            'n_startYear': 'first',\n",
    "            'n_endYear': 'first',\n",
    "            'centroid': 'first',\n",
    "            'length': 'first',\n",
    "            'area': 'first',\n",
    "            'wkt': 'first',\n",
    "            'geojson': 'first'}\n",
    "\n",
    "for col in agg_dict.copy():\n",
    "    if col not in merged_df.columns:\n",
    "        del agg_dict[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "mf = merged_df.groupby('id').agg(agg_dict).reset_index()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T14:41:57.630445031Z",
     "start_time": "2023-12-12T14:41:56.041716993Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "cxP9e2Cu11wB",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:41:59.083996785Z",
     "start_time": "2023-12-12T14:41:59.075816400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2015 entries, 0 to 2014\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     2015 non-null   object \n",
      " 1   keywords               2015 non-null   object \n",
      " 2   type                   2015 non-null   object \n",
      " 3   geotype                2014 non-null   object \n",
      " 4   geompred               2014 non-null   object \n",
      " 5   geom                   2015 non-null   object \n",
      " 6   temporalCoverage       2015 non-null   object \n",
      " 7   datePublished          2015 non-null   object \n",
      " 8   license                2015 non-null   object \n",
      " 9   creator                2009 non-null   object \n",
      " 10  includedInDataCatalog  2015 non-null   object \n",
      " 11  distribution           2013 non-null   object \n",
      " 12  publisher              2015 non-null   object \n",
      " 13  filteredgeom           2015 non-null   object \n",
      " 14  dt_startDate           1813 non-null   object \n",
      " 15  dt_endDate             1813 non-null   object \n",
      " 16  n_startYear            1813 non-null   float64\n",
      " 17  n_endYear              1628 non-null   float64\n",
      " 18  centroid               2015 non-null   object \n",
      " 19  length                 2014 non-null   float64\n",
      " 20  area                   612 non-null    float64\n",
      " 21  wkt                    2014 non-null   object \n",
      " 22  geojson                2014 non-null   object \n",
      "dtypes: float64(4), object(19)\n",
      "memory usage: 362.2+ KB\n"
     ]
    }
   ],
   "source": [
    "mf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "dxjRZwaJCQjH",
    "ExecuteTime": {
     "end_time": "2023-12-12T14:42:45.026176672Z",
     "start_time": "2023-12-12T14:42:44.975958608Z"
    }
   },
   "outputs": [],
   "source": [
    "mf.to_parquet('mdpProduct.parquet')\n",
    "# mf.to_csv('mdpProduct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
